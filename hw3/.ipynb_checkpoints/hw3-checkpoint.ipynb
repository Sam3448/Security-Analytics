{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Build a classifier using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that gives a visual representation of the decision tree\n",
    "def Decision_Tree_Image(decision_tree, feature_names, name=\"temp\"):\n",
    "    # Export our decision tree to graphviz format\n",
    "    dot_file = tree.export_graphviz(decision_tree, out_file='images/' + name + '.dot', feature_names=feature_names)\n",
    "    \n",
    "    # Call graphviz to make an image file from our decision tree\n",
    "    os.system(\"dot -Tpng images/\" + name + \".dot -o images/\" + name + \".png\")\n",
    "    \n",
    "    # Return the .png image so we can see it\n",
    "    return Image(filename='images/' + name + '.png')\n",
    "\n",
    "# A function to plot the data\n",
    "def Plot_Data(data, v1, v2, tv):\n",
    "    # Make the plot square\n",
    "    plt.rcParams['figure.figsize'] = [12.0, 8.0]\n",
    "    \n",
    "    # Color\n",
    "    color = [\"red\" if x == 0 else \"blue\" for x in data[tv]]\n",
    "    \n",
    "    # Plot and label\n",
    "    plt.scatter(data[v1], data[v2], c=color, s=50)\n",
    "    plt.xlabel(v1)\n",
    "    plt.ylabel(v2)\n",
    "    plt.xlim([min(data[v1]) - 1, max(data[v1]) + 1])\n",
    "    plt.ylim([min(data[v2]) - .05, max(data[v2]) + .05])\n",
    "    \n",
    "def Decision_Surface(x, y, model, cell_size=.01):\n",
    "    # Get blob sizes for shading\n",
    "    x = (min(x), max(x))\n",
    "    y = (min(y), max(y))\n",
    "    x_step = (x[1] - x[0]) * cell_size\n",
    "    y_step = (y[1] - y[0]) * cell_size\n",
    "\n",
    "    # Create blobs\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    \n",
    "    for i in np.arange(x[0], x[1], x_step):\n",
    "        for j in np.arange(y[0], y[1], y_step):\n",
    "            y_values.append(float(i))\n",
    "            x_values.append(float(j))\n",
    "    \n",
    "    data_blob = pd.DataFrame({\"x\": x_values, \"y\": y_values})\n",
    "\n",
    "    # Predict the blob labels\n",
    "    label= decision_tree.predict(data_blob)\n",
    "    \n",
    "    # Color and plot them\n",
    "    color = [\"red\" if l == 0 else \"blue\" for l in label]\n",
    "    plt.scatter(data_blob['y'], data_blob['x'], marker='o', edgecolor='black', linewidth='0', c=color, alpha=0.3)\n",
    "    \n",
    "    # Get the raw decision tree rules\n",
    "    decision_tree_raw = []\n",
    "    for feature, left_c, right_c, threshold, value in zip(decision_tree.tree_.feature, \n",
    "                                                          decision_tree.tree_.children_left, \n",
    "                                                          decision_tree.tree_.children_right, \n",
    "                                                          decision_tree.tree_.threshold, \n",
    "                                                          decision_tree.tree_.value):\n",
    "        decision_tree_raw.append([feature, left_c, right_c, threshold, value])\n",
    "\n",
    "    # Plot the data\n",
    "    Plot_Data(data, \"humor\", \"number_pets\", \"success\")\n",
    "\n",
    "    # Used for formatting the boundry lines\n",
    "    currentAxis = plt.gca()\n",
    "    line_color = \"black\"\n",
    "    line_width = 3\n",
    "\n",
    "    # For each rule\n",
    "    for row in decision_tree_raw:\n",
    "        feature, left_c, right_c, threshold, value = row\n",
    "\n",
    "        if threshold != -2:\n",
    "            if feature == 0:\n",
    "                plt.plot([20, 100], [threshold, threshold], c=line_color, linewidth=line_width)\n",
    "            else:\n",
    "                plt.plot([threshold, threshold], [0, 5], c=line_color, linewidth=line_width)\n",
    "\n",
    "    plt.xlim([min(x) - 1, max(x) + 1])\n",
    "    plt.ylim([min(y) - .05, max(y) + .05])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check_sum</th>\n",
       "      <th>compile_date</th>\n",
       "      <th>datadir_IMAGE_DIRECTORY_ENTRY_BASERELOC_size</th>\n",
       "      <th>datadir_IMAGE_DIRECTORY_ENTRY_EXPORT_size</th>\n",
       "      <th>datadir_IMAGE_DIRECTORY_ENTRY_IAT_size</th>\n",
       "      <th>datadir_IMAGE_DIRECTORY_ENTRY_IMPORT_size</th>\n",
       "      <th>datadir_IMAGE_DIRECTORY_ENTRY_RESOURCE_size</th>\n",
       "      <th>debug_size</th>\n",
       "      <th>export_size</th>\n",
       "      <th>generated_check_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_vasize_upx3</th>\n",
       "      <th>size_code</th>\n",
       "      <th>size_image</th>\n",
       "      <th>size_initdata</th>\n",
       "      <th>size_uninit</th>\n",
       "      <th>std_section_names</th>\n",
       "      <th>total_size_pe</th>\n",
       "      <th>virtual_address</th>\n",
       "      <th>virtual_size</th>\n",
       "      <th>virtual_size_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>585810474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13824</td>\n",
       "      <td>180224</td>\n",
       "      <td>43008</td>\n",
       "      <td>65536</td>\n",
       "      <td>0</td>\n",
       "      <td>85504</td>\n",
       "      <td>4096</td>\n",
       "      <td>13352</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1218437803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>100</td>\n",
       "      <td>1048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>20480</td>\n",
       "      <td>12288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20480</td>\n",
       "      <td>4096</td>\n",
       "      <td>3346</td>\n",
       "      <td>2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98299</td>\n",
       "      <td>1297813288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>40</td>\n",
       "      <td>1660</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>113512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36864</td>\n",
       "      <td>53248</td>\n",
       "      <td>12288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64512</td>\n",
       "      <td>4096</td>\n",
       "      <td>33504</td>\n",
       "      <td>5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104924</td>\n",
       "      <td>708992537</td>\n",
       "      <td>4612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2842</td>\n",
       "      <td>6144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67072</td>\n",
       "      <td>114688</td>\n",
       "      <td>13824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81920</td>\n",
       "      <td>4096</td>\n",
       "      <td>66596</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150326</td>\n",
       "      <td>1276781438</td>\n",
       "      <td>188</td>\n",
       "      <td>154</td>\n",
       "      <td>308</td>\n",
       "      <td>180</td>\n",
       "      <td>84152</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>150326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6656</td>\n",
       "      <td>110592</td>\n",
       "      <td>89088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97280</td>\n",
       "      <td>4096</td>\n",
       "      <td>6532</td>\n",
       "      <td>2074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   check_sum  compile_date  datadir_IMAGE_DIRECTORY_ENTRY_BASERELOC_size  \\\n",
       "0          0     585810474                                             0   \n",
       "1          0    1218437803                                             0   \n",
       "2      98299    1297813288                                             0   \n",
       "3     104924     708992537                                          4612   \n",
       "4     150326    1276781438                                           188   \n",
       "\n",
       "   datadir_IMAGE_DIRECTORY_ENTRY_EXPORT_size  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                        154   \n",
       "\n",
       "   datadir_IMAGE_DIRECTORY_ENTRY_IAT_size  \\\n",
       "0                                      44   \n",
       "1                                     468   \n",
       "2                                     372   \n",
       "3                                       0   \n",
       "4                                     308   \n",
       "\n",
       "   datadir_IMAGE_DIRECTORY_ENTRY_IMPORT_size  \\\n",
       "0                                         40   \n",
       "1                                        100   \n",
       "2                                         40   \n",
       "3                                       2842   \n",
       "4                                        180   \n",
       "\n",
       "   datadir_IMAGE_DIRECTORY_ENTRY_RESOURCE_size  debug_size  export_size  \\\n",
       "0                                            0           0            0   \n",
       "1                                         1048           0            0   \n",
       "2                                         1660          28            0   \n",
       "3                                         6144           0            0   \n",
       "4                                        84152           0          154   \n",
       "\n",
       "   generated_check_sum       ...        sec_vasize_upx3 size_code  size_image  \\\n",
       "0                98624       ...                    0.0     13824      180224   \n",
       "1                53913       ...                    0.0      4096       20480   \n",
       "2               113512       ...                    0.0     36864       53248   \n",
       "3               104924       ...                    0.0     67072      114688   \n",
       "4               150326       ...                    0.0      6656      110592   \n",
       "\n",
       "   size_initdata  size_uninit  std_section_names  total_size_pe  \\\n",
       "0          43008        65536                  0          85504   \n",
       "1          12288            0                  1          20480   \n",
       "2          12288            0                  1          64512   \n",
       "3          13824            0                  0          81920   \n",
       "4          89088            0                  0          97280   \n",
       "\n",
       "   virtual_address  virtual_size  virtual_size_2  \n",
       "0             4096         13352           65536  \n",
       "1             4096          3346            2182  \n",
       "2             4096         33504            5156  \n",
       "3             4096         66596             456  \n",
       "4             4096          6532            2074  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=pd.read_csv(\"homework3.csv\")\n",
    "vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_sum\n"
     ]
    }
   ],
   "source": [
    "col_names = []\n",
    "for s in vec.columns:\n",
    "    if s != \"label\":\n",
    "        col_names.append(s)\n",
    "print col_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec[col_names]\n",
    "Y = vec[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")\n",
    "decision_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.920\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy = %.3f\" % (metrics.accuracy_score(decision_tree.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2: 10 Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    # Get the number of users\n",
    "    n = len(target)\n",
    "    # Count how frequently each unique value occurs\n",
    "    counts = np.bincount(target).astype(float)\n",
    "    # Initialize entropy\n",
    "    entropy = 0\n",
    "    # If the split is perfect, return 0\n",
    "    if len(counts) <= 1 or 0 in counts:\n",
    "        return entropy\n",
    "    # Otherwise, for each possible value, update entropy\n",
    "    for count in counts:\n",
    "        entropy += math.log(count/n, len(counts)) * count/n\n",
    "    # Return entropy\n",
    "    return -1 * entropy\n",
    "\n",
    "def information_gain(feature, threshold, target):\n",
    "    # Dealing with numpy arrays makes this slightly easier\n",
    "    target = np.array(target)\n",
    "    feature = np.array(feature)\n",
    "    # Cut the feature vector on the threshold\n",
    "    feature = (feature < threshold)\n",
    "    # Initialize information gain with the parent entropy\n",
    "    ig = entropy(target)\n",
    "    # For both sides of the threshold, update information gain\n",
    "    for level, count in zip([0, 1], np.bincount(feature).astype(float)):\n",
    "        ig -= count/len(feature) * entropy(target[feature == level])\n",
    "    # Return information gain\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = []\n",
    "for i in Y:\n",
    "    if i == \"good\":\n",
    "        target_label.append(0)\n",
    "    else:\n",
    "        target_label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ranking = {}\n",
    "threshold = 3.2\n",
    "for i in X.columns:\n",
    "    score = information_gain(X[i], threshold, target_label)\n",
    "    feature_ranking[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = sorted(feature_ranking.items(), lambda x, y: cmp(x[1], y[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debug_size', 0.46844462813835852)\n",
      "('sec_rawsize_reloc', 0.3226822647613829)\n",
      "('sec_rawptr_reloc', 0.30291347056088036)\n",
      "('sec_vasize_reloc', 0.30291347056088036)\n",
      "('datadir_IMAGE_DIRECTORY_ENTRY_BASERELOC_size', 0.28406893289906648)\n",
      "('check_sum', 0.25760895169765585)\n",
      "('sec_entropy_reloc', 0.1983440151760999)\n",
      "('pe_minorlink', 0.19124714854527902)\n",
      "('sec_vasize_text', 0.17378379914476594)\n",
      "('sec_rawptr_text', 0.17378379914476594)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(ranked[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3: Two logistic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
